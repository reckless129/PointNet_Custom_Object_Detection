{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\wangp\\\\Anaconda3\\\\envs\\\\open3d\\\\python.exe'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v1 as tf\n",
    "\n",
    "# tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "import socket\n",
    "import glob\n",
    "\n",
    "import os\n",
    "import sys\n",
    " \n",
    "import provider\n",
    "import tf_util\n",
    "from model import *\n",
    "print(\"success\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 12\n",
    "BATCH_SIZE_EVAL = 12\n",
    "NUM_POINT = 4096\n",
    "MAX_EPOCH = 61\n",
    "BASE_LEARNING_RATE = 0.001\n",
    "GPU_INDEX = 0\n",
    "MOMENTUM = 0.9\n",
    "OPTIMIZER = 'adam'\n",
    "DECAY_STEP = 300000\n",
    "DECAY_RATE = 0.5\n",
    "\n",
    "LOG_DIR = 'log'\n",
    "if not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)\n",
    "os.system('cp model.py %s' % (LOG_DIR)) # bkp of model def\n",
    "#os.system('cp train.py %s' % (LOG_DIR)) # bkp of train procedure\n",
    "LOG_FOUT = open(os.path.join(LOG_DIR, 'log_train.txt'), 'w')\n",
    "# LOG_FOUT.write(str(FLAGS)+'\\n')\n",
    "\n",
    "MAX_NUM_POINT = 4096\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "BN_INIT_DECAY = 0.5\n",
    "BN_DECAY_DECAY_RATE = 0.5\n",
    "#BN_DECAY_DECAY_STEP = float(DECAY_STEP * 2)\n",
    "BN_DECAY_DECAY_STEP = float(DECAY_STEP)\n",
    "BN_DECAY_CLIP = 0.99\n",
    "\n",
    "HOSTNAME = socket.gethostname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 4096, 6)\n",
      "(360, 4096)\n"
     ]
    }
   ],
   "source": [
    "#Normalize data\n",
    "xmax = 3.0\n",
    "xmin = -3.0\n",
    "\n",
    "DATASET_DIR = 'data/'\n",
    "f = h5py.File(DATASET_DIR+ 'd0.h5','r')\n",
    "NUM_FRAMES = f['data'].shape[0]\n",
    "\n",
    "total_data = np.zeros((6*NUM_FRAMES,4096, 6))\n",
    "total_label = np.zeros((6*NUM_FRAMES,4096))\n",
    "\n",
    "for i in range (0,6):\n",
    "    f = h5py.File(DATASET_DIR+ 'd' +str(i)+'.h5','r')\n",
    "    data = f['data']\n",
    "    label = f['label']\n",
    "    total_data[i*len(data):(i+1)*len(data),:,0:3] = (data[:, :, 0:3] - xmin) / (xmax  - xmin )\n",
    "    total_data[i*len(data):(i+1)*len(data),:,3:6] = data[:, :, 3:6]\n",
    "    total_label[i*len(data):(i+1)*len(data),:] = label[:, :]\n",
    "    \n",
    "print(total_data.shape)\n",
    "print(total_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_range : 0.29408538341522217 0.7170508503913879\n",
      "y_range : 0.317680299282074 0.6883880098660787\n",
      "z_range : 0.5334503278136253 0.8151378035545349\n",
      "r_range : 0.0 0.004490316845476627\n",
      "g_range : 1.5118113878997974e-05 0.004506220109760761\n",
      "b_range : 0.0 0.004490316845476627\n"
     ]
    }
   ],
   "source": [
    "features = [\"x\",\"y\",\"z\",\"r\",\"g\",\"b\"]\n",
    "for i in range(6): \n",
    "    print(features[i] + \"_range :\", np.min(total_data[:, :, i]), np.max(total_data[:, :, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 4096, 6), (360, 4096))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = total_data\n",
    "y = total_label\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_range : 0.29408538341522217 0.7170508503913879\n",
      "y_range : 0.317680299282074 0.6883880098660787\n",
      "z_range : 0.5334503278136253 0.8151378035545349\n",
      "r_range : 0.0 0.004490316845476627\n",
      "g_range : 1.5118113878997974e-05 0.004506220109760761\n",
      "b_range : 0.0 0.004490316845476627\n"
     ]
    }
   ],
   "source": [
    "features = [\"x\",\"y\",\"z\",\"r\",\"g\",\"b\"]\n",
    "for i in range(6): \n",
    "    print(features[i] + \"_range :\", np.min(total_data[:, :, i]), np.max(total_data[:, :, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(324, 4096, 6) (324, 4096)\n",
      "(36, 4096, 6) (36, 4096)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_label, test_label = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "print(train_data.shape, train_label.shape)\n",
    "print(test_data.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"fc2/Relu:0\", shape=(12, 128), dtype=float32, device=/device:GPU:0)\n",
      "**** EPOCH 000 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.836770\n",
      "accuracy: 0.844236\n",
      "----\n",
      "eval mean loss: 0.213030\n",
      "eval accuracy: 0.926222\n",
      "eval avg class acc: 0.924897\n",
      "Model saved in file: log\\model.ckpt\n",
      "**** EPOCH 001 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.175154\n",
      "accuracy: 0.934269\n",
      "----\n",
      "eval mean loss: 0.155829\n",
      "eval accuracy: 0.927233\n",
      "eval avg class acc: 0.935186\n",
      "**** EPOCH 002 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.141147\n",
      "accuracy: 0.939319\n",
      "----\n",
      "eval mean loss: 0.117492\n",
      "eval accuracy: 0.951199\n",
      "eval avg class acc: 0.898977\n",
      "**** EPOCH 003 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.120176\n",
      "accuracy: 0.947603\n",
      "----\n",
      "eval mean loss: 0.116517\n",
      "eval accuracy: 0.949795\n",
      "eval avg class acc: 0.923720\n",
      "**** EPOCH 004 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.114948\n",
      "accuracy: 0.949599\n",
      "----\n",
      "eval mean loss: 0.102826\n",
      "eval accuracy: 0.949761\n",
      "eval avg class acc: 0.877463\n",
      "**** EPOCH 005 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.104470\n",
      "accuracy: 0.954946\n",
      "----\n",
      "eval mean loss: 0.099031\n",
      "eval accuracy: 0.956082\n",
      "eval avg class acc: 0.932437\n",
      "**** EPOCH 006 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.100558\n",
      "accuracy: 0.956496\n",
      "----\n",
      "eval mean loss: 0.097655\n",
      "eval accuracy: 0.953932\n",
      "eval avg class acc: 0.935619\n",
      "**** EPOCH 007 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.100256\n",
      "accuracy: 0.957073\n",
      "----\n",
      "eval mean loss: 0.091808\n",
      "eval accuracy: 0.962619\n",
      "eval avg class acc: 0.949684\n",
      "**** EPOCH 008 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.100161\n",
      "accuracy: 0.955778\n",
      "----\n",
      "eval mean loss: 0.101544\n",
      "eval accuracy: 0.951090\n",
      "eval avg class acc: 0.933567\n",
      "**** EPOCH 009 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.102022\n",
      "accuracy: 0.954370\n",
      "----\n",
      "eval mean loss: 0.086401\n",
      "eval accuracy: 0.958089\n",
      "eval avg class acc: 0.887980\n",
      "**** EPOCH 010 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.083894\n",
      "accuracy: 0.964712\n",
      "----\n",
      "eval mean loss: 0.072145\n",
      "eval accuracy: 0.969449\n",
      "eval avg class acc: 0.923710\n",
      "Model saved in file: log\\model.ckpt\n",
      "**** EPOCH 011 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.082889\n",
      "accuracy: 0.964270\n",
      "----\n",
      "eval mean loss: 0.071278\n",
      "eval accuracy: 0.968275\n",
      "eval avg class acc: 0.935375\n",
      "**** EPOCH 012 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.075503\n",
      "accuracy: 0.968362\n",
      "----\n",
      "eval mean loss: 0.092967\n",
      "eval accuracy: 0.958198\n",
      "eval avg class acc: 0.901689\n",
      "**** EPOCH 013 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.076266\n",
      "accuracy: 0.968788\n",
      "----\n",
      "eval mean loss: 0.085279\n",
      "eval accuracy: 0.963331\n",
      "eval avg class acc: 0.954930\n",
      "**** EPOCH 014 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.066300\n",
      "accuracy: 0.972681\n",
      "----\n",
      "eval mean loss: 0.083257\n",
      "eval accuracy: 0.967753\n",
      "eval avg class acc: 0.957747\n",
      "**** EPOCH 015 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.064787\n",
      "accuracy: 0.973500\n",
      "----\n",
      "eval mean loss: 0.073698\n",
      "eval accuracy: 0.970785\n",
      "eval avg class acc: 0.943810\n",
      "**** EPOCH 016 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.072551\n",
      "accuracy: 0.969913\n",
      "----\n",
      "eval mean loss: 0.075166\n",
      "eval accuracy: 0.968201\n",
      "eval avg class acc: 0.939023\n",
      "**** EPOCH 017 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.070005\n",
      "accuracy: 0.970445\n",
      "----\n",
      "eval mean loss: 0.068046\n",
      "eval accuracy: 0.974589\n",
      "eval avg class acc: 0.961719\n",
      "**** EPOCH 018 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.063728\n",
      "accuracy: 0.974539\n",
      "----\n",
      "eval mean loss: 0.069628\n",
      "eval accuracy: 0.977532\n",
      "eval avg class acc: 0.966363\n",
      "**** EPOCH 019 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.065753\n",
      "accuracy: 0.972683\n",
      "----\n",
      "eval mean loss: 0.066587\n",
      "eval accuracy: 0.967753\n",
      "eval avg class acc: 0.940469\n",
      "**** EPOCH 020 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.056038\n",
      "accuracy: 0.976757\n",
      "----\n",
      "eval mean loss: 0.070035\n",
      "eval accuracy: 0.971042\n",
      "eval avg class acc: 0.930747\n",
      "Model saved in file: log\\model.ckpt\n",
      "**** EPOCH 021 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.057568\n",
      "accuracy: 0.977104\n",
      "----\n",
      "eval mean loss: 0.062581\n",
      "eval accuracy: 0.976969\n",
      "eval avg class acc: 0.971120\n",
      "**** EPOCH 022 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.070734\n",
      "accuracy: 0.969691\n",
      "----\n",
      "eval mean loss: 0.086299\n",
      "eval accuracy: 0.962402\n",
      "eval avg class acc: 0.910348\n",
      "**** EPOCH 023 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.071037\n",
      "accuracy: 0.972215\n",
      "----\n",
      "eval mean loss: 0.061097\n",
      "eval accuracy: 0.972866\n",
      "eval avg class acc: 0.932814\n",
      "**** EPOCH 024 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.067041\n",
      "accuracy: 0.972117\n",
      "----\n",
      "eval mean loss: 0.051244\n",
      "eval accuracy: 0.977268\n",
      "eval avg class acc: 0.957374\n",
      "**** EPOCH 025 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.063347\n",
      "accuracy: 0.974979\n",
      "----\n",
      "eval mean loss: 0.053181\n",
      "eval accuracy: 0.977173\n",
      "eval avg class acc: 0.952312\n",
      "**** EPOCH 026 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.048751\n",
      "accuracy: 0.980814\n",
      "----\n",
      "eval mean loss: 0.074455\n",
      "eval accuracy: 0.971517\n",
      "eval avg class acc: 0.958158\n",
      "**** EPOCH 027 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.053792\n",
      "accuracy: 0.977388\n",
      "----\n",
      "eval mean loss: 0.056910\n",
      "eval accuracy: 0.975505\n",
      "eval avg class acc: 0.971030\n",
      "**** EPOCH 028 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.050185\n",
      "accuracy: 0.979753\n",
      "----\n",
      "eval mean loss: 0.072825\n",
      "eval accuracy: 0.966376\n",
      "eval avg class acc: 0.918814\n",
      "**** EPOCH 029 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.048737\n",
      "accuracy: 0.980621\n",
      "----\n",
      "eval mean loss: 0.070134\n",
      "eval accuracy: 0.970045\n",
      "eval avg class acc: 0.921408\n",
      "**** EPOCH 030 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.050809\n",
      "accuracy: 0.980469\n",
      "----\n",
      "eval mean loss: 0.068948\n",
      "eval accuracy: 0.974691\n",
      "eval avg class acc: 0.963703\n",
      "Model saved in file: log\\model.ckpt\n",
      "**** EPOCH 031 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.045779\n",
      "accuracy: 0.982164\n",
      "----\n",
      "eval mean loss: 0.058619\n",
      "eval accuracy: 0.975206\n",
      "eval avg class acc: 0.963042\n",
      "**** EPOCH 032 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.045256\n",
      "accuracy: 0.982541\n",
      "----\n",
      "eval mean loss: 0.060250\n",
      "eval accuracy: 0.977119\n",
      "eval avg class acc: 0.957640\n",
      "**** EPOCH 033 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.043844\n",
      "accuracy: 0.983079\n",
      "----\n",
      "eval mean loss: 0.061157\n",
      "eval accuracy: 0.976312\n",
      "eval avg class acc: 0.966829\n",
      "**** EPOCH 034 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.045739\n",
      "accuracy: 0.981698\n",
      "----\n",
      "eval mean loss: 0.060149\n",
      "eval accuracy: 0.972005\n",
      "eval avg class acc: 0.944700\n",
      "**** EPOCH 035 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.042769\n",
      "accuracy: 0.982755\n",
      "----\n",
      "eval mean loss: 0.057187\n",
      "eval accuracy: 0.976508\n",
      "eval avg class acc: 0.953710\n",
      "**** EPOCH 036 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.043620\n",
      "accuracy: 0.982463\n",
      "----\n",
      "eval mean loss: 0.071358\n",
      "eval accuracy: 0.969293\n",
      "eval avg class acc: 0.917513\n",
      "**** EPOCH 037 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.046209\n",
      "accuracy: 0.982319\n",
      "----\n",
      "eval mean loss: 0.067031\n",
      "eval accuracy: 0.976101\n",
      "eval avg class acc: 0.945226\n",
      "**** EPOCH 038 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.042734\n",
      "accuracy: 0.982900\n",
      "----\n",
      "eval mean loss: 0.059426\n",
      "eval accuracy: 0.976969\n",
      "eval avg class acc: 0.948521\n",
      "**** EPOCH 039 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.042695\n",
      "accuracy: 0.984212\n",
      "----\n",
      "eval mean loss: 0.052505\n",
      "eval accuracy: 0.980733\n",
      "eval avg class acc: 0.970353\n",
      "**** EPOCH 040 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.042810\n",
      "accuracy: 0.983313\n",
      "----\n",
      "eval mean loss: 0.076108\n",
      "eval accuracy: 0.973579\n",
      "eval avg class acc: 0.936233\n",
      "Model saved in file: log\\model.ckpt\n",
      "**** EPOCH 041 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.041928\n",
      "accuracy: 0.983774\n",
      "----\n",
      "eval mean loss: 0.068187\n",
      "eval accuracy: 0.978841\n",
      "eval avg class acc: 0.953286\n",
      "**** EPOCH 042 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.042971\n",
      "accuracy: 0.982949\n",
      "----\n",
      "eval mean loss: 0.056705\n",
      "eval accuracy: 0.976223\n",
      "eval avg class acc: 0.951953\n",
      "**** EPOCH 043 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.038830\n",
      "accuracy: 0.984762\n",
      "----\n",
      "eval mean loss: 0.073581\n",
      "eval accuracy: 0.973206\n",
      "eval avg class acc: 0.928123\n",
      "**** EPOCH 044 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.038552\n",
      "accuracy: 0.985415\n",
      "----\n",
      "eval mean loss: 0.060338\n",
      "eval accuracy: 0.975735\n",
      "eval avg class acc: 0.942244\n",
      "**** EPOCH 045 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.037297\n",
      "accuracy: 0.986167\n",
      "----\n",
      "eval mean loss: 0.075722\n",
      "eval accuracy: 0.968058\n",
      "eval avg class acc: 0.917067\n",
      "**** EPOCH 046 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.043732\n",
      "accuracy: 0.983553\n",
      "----\n",
      "eval mean loss: 0.075626\n",
      "eval accuracy: 0.973355\n",
      "eval avg class acc: 0.960724\n",
      "**** EPOCH 047 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.034002\n",
      "accuracy: 0.986986\n",
      "----\n",
      "eval mean loss: 0.059377\n",
      "eval accuracy: 0.976671\n",
      "eval avg class acc: 0.941514\n",
      "**** EPOCH 048 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.033699\n",
      "accuracy: 0.987128\n",
      "----\n",
      "eval mean loss: 0.097714\n",
      "eval accuracy: 0.970913\n",
      "eval avg class acc: 0.925528\n",
      "**** EPOCH 049 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.040719\n",
      "accuracy: 0.983478\n",
      "----\n",
      "eval mean loss: 0.066944\n",
      "eval accuracy: 0.976095\n",
      "eval avg class acc: 0.963286\n",
      "**** EPOCH 050 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.038237\n",
      "accuracy: 0.985565\n",
      "----\n",
      "eval mean loss: 0.068831\n",
      "eval accuracy: 0.971110\n",
      "eval avg class acc: 0.929098\n",
      "Model saved in file: log\\model.ckpt\n",
      "**** EPOCH 051 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.034021\n",
      "accuracy: 0.987274\n",
      "----\n",
      "eval mean loss: 0.066043\n",
      "eval accuracy: 0.975518\n",
      "eval avg class acc: 0.951267\n",
      "**** EPOCH 052 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.032176\n",
      "accuracy: 0.988271\n",
      "----\n",
      "eval mean loss: 0.108573\n",
      "eval accuracy: 0.966987\n",
      "eval avg class acc: 0.910237\n",
      "**** EPOCH 053 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.037259\n",
      "accuracy: 0.985405\n",
      "----\n",
      "eval mean loss: 0.046744\n",
      "eval accuracy: 0.979594\n",
      "eval avg class acc: 0.946873\n",
      "**** EPOCH 054 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.035579\n",
      "accuracy: 0.986792\n",
      "----\n",
      "eval mean loss: 0.076584\n",
      "eval accuracy: 0.977017\n",
      "eval avg class acc: 0.938712\n",
      "**** EPOCH 055 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.037277\n",
      "accuracy: 0.985838\n",
      "----\n",
      "eval mean loss: 0.051370\n",
      "eval accuracy: 0.979506\n",
      "eval avg class acc: 0.970794\n",
      "**** EPOCH 056 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.028749\n",
      "accuracy: 0.989009\n",
      "----\n",
      "eval mean loss: 0.035019\n",
      "eval accuracy: 0.985101\n",
      "eval avg class acc: 0.971411\n",
      "**** EPOCH 057 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.027763\n",
      "accuracy: 0.989627\n",
      "----\n",
      "eval mean loss: 0.057886\n",
      "eval accuracy: 0.980265\n",
      "eval avg class acc: 0.960223\n",
      "**** EPOCH 058 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.032558\n",
      "accuracy: 0.987501\n",
      "----\n",
      "eval mean loss: 0.072979\n",
      "eval accuracy: 0.975254\n",
      "eval avg class acc: 0.943612\n",
      "**** EPOCH 059 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.040602\n",
      "accuracy: 0.984327\n",
      "----\n",
      "eval mean loss: 0.078516\n",
      "eval accuracy: 0.972419\n",
      "eval avg class acc: 0.916394\n",
      "**** EPOCH 060 ****\n",
      "----\n",
      "Current batch/total batch num: 0/27\n",
      "mean loss: 0.033114\n",
      "accuracy: 0.987654\n",
      "----\n",
      "eval mean loss: 0.056580\n",
      "eval accuracy: 0.980564\n",
      "eval avg class acc: 0.976046\n",
      "Model saved in file: log\\model.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def log_string(out_str):\n",
    "    LOG_FOUT.write(out_str+'\\n')\n",
    "    LOG_FOUT.flush()\n",
    "    print(out_str)\n",
    "\n",
    "\n",
    "def get_learning_rate(batch):\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "                        BASE_LEARNING_RATE,  # Base learning rate.\n",
    "                        batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "                        DECAY_STEP,          # Decay step.\n",
    "                        DECAY_RATE,          # Decay rate.\n",
    "                        staircase=True)\n",
    "    learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!!\n",
    "    return learning_rate        \n",
    "\n",
    "def get_bn_decay(batch):\n",
    "    bn_momentum = tf.train.exponential_decay(\n",
    "                      BN_INIT_DECAY,\n",
    "                      batch*BATCH_SIZE,\n",
    "                      BN_DECAY_DECAY_STEP,\n",
    "                      BN_DECAY_DECAY_RATE,\n",
    "                      staircase=True)\n",
    "    bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n",
    "    return bn_decay\n",
    "\n",
    "def train():\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.device('/gpu:'+str(GPU_INDEX)):\n",
    "            pointclouds_pl, labels_pl = placeholder_inputs(BATCH_SIZE, NUM_POINT)\n",
    "            is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "            \n",
    "            # Note the global_step=batch parameter to minimize. \n",
    "            # That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.\n",
    "            batch = tf.Variable(0)\n",
    "            bn_decay = get_bn_decay(batch)\n",
    "            tf.summary.scalar('bn_decay', bn_decay)\n",
    "\n",
    "            # Get model and loss \n",
    "            pred = get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay)\n",
    "            loss = get_loss(pred, labels_pl)\n",
    "            tf.summary.scalar('loss', loss)\n",
    "\n",
    "            correct = tf.equal(tf.argmax(pred, 2), tf.to_int64(labels_pl))\n",
    "            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE*NUM_POINT)\n",
    "            tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "            # Get training operator\n",
    "            learning_rate = get_learning_rate(batch)\n",
    "            tf.summary.scalar('learning_rate', learning_rate)\n",
    "            if OPTIMIZER == 'momentum':\n",
    "                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n",
    "            elif OPTIMIZER == 'adam':\n",
    "                optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            train_op = optimizer.minimize(loss, global_step=batch)\n",
    "            \n",
    "            # Add ops to save and restore all the variables.\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "        # Create a session\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        config.allow_soft_placement = True\n",
    "        config.log_device_placement = True\n",
    "        sess = tf.Session(config=config)\n",
    "\n",
    "        # Add summary writers\n",
    "        merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'train'),\n",
    "                                  sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'test'))\n",
    "\n",
    "        # Init variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init, {is_training_pl:True})\n",
    "\n",
    "        ops = {'pointclouds_pl': pointclouds_pl,\n",
    "               'labels_pl': labels_pl,\n",
    "               'is_training_pl': is_training_pl,\n",
    "               'pred': pred,\n",
    "               'loss': loss,\n",
    "               'train_op': train_op,\n",
    "               'merged': merged,\n",
    "               'step': batch}\n",
    "\n",
    "        for epoch in range(MAX_EPOCH):\n",
    "            log_string('**** EPOCH %03d ****' % (epoch))\n",
    "            sys.stdout.flush()\n",
    "             \n",
    "            train_one_epoch(sess, ops, train_writer)\n",
    "            eval_one_epoch(sess, ops, test_writer)\n",
    "            \n",
    "            # Save the variables to disk.\n",
    "            if epoch % 10 == 0:\n",
    "                save_path = saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"))\n",
    "                log_string(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(sess, ops, train_writer):\n",
    "    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n",
    "    is_training = True\n",
    "    \n",
    "    log_string('----')\n",
    "    current_data, current_label, _ = provider.shuffle_data(train_data[:,0:NUM_POINT,:], train_label) \n",
    "    \n",
    "    file_size = current_data.shape[0]\n",
    "    num_batches = file_size // BATCH_SIZE\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_seen = 0\n",
    "    loss_sum = 0\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Current batch/total batch num: %d/%d'%(batch_idx,num_batches))\n",
    "        start_idx = batch_idx * BATCH_SIZE\n",
    "        end_idx = (batch_idx+1) * BATCH_SIZE\n",
    "        \n",
    "        feed_dict = {ops['pointclouds_pl']: current_data[start_idx:end_idx, :, :],\n",
    "                     ops['labels_pl']: current_label[start_idx:end_idx],\n",
    "                     ops['is_training_pl']: is_training,}\n",
    "        summary, step, _, loss_val, pred_val = sess.run([ops['merged'], ops['step'], ops['train_op'], ops['loss'], ops['pred']],\n",
    "                                         feed_dict=feed_dict)\n",
    "        train_writer.add_summary(summary, step)\n",
    "        pred_val = np.argmax(pred_val, 2)\n",
    "        correct = np.sum(pred_val == current_label[start_idx:end_idx])\n",
    "        total_correct += correct\n",
    "        total_seen += (BATCH_SIZE*NUM_POINT)\n",
    "        loss_sum += loss_val\n",
    "    \n",
    "    log_string('mean loss: %f' % (loss_sum / float(num_batches)))\n",
    "    log_string('accuracy: %f' % (total_correct / float(total_seen)))\n",
    "\n",
    "        \n",
    "def eval_one_epoch(sess, ops, test_writer):\n",
    "    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n",
    "    is_training = False\n",
    "    total_correct = 0\n",
    "    total_seen = 0\n",
    "    loss_sum = 0\n",
    "    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n",
    "    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n",
    "    \n",
    "    log_string('----')\n",
    "    current_data = test_data[:,0:NUM_POINT,:]\n",
    "    current_label = np.squeeze(test_label)\n",
    "    \n",
    "    file_size = current_data.shape[0]\n",
    "    num_batches = file_size // BATCH_SIZE_EVAL\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * BATCH_SIZE_EVAL\n",
    "        end_idx = (batch_idx+1) * BATCH_SIZE_EVAL\n",
    "\n",
    "        feed_dict = {ops['pointclouds_pl']: current_data[start_idx:end_idx, :, :],\n",
    "                     ops['labels_pl']: current_label[start_idx:end_idx],\n",
    "                     ops['is_training_pl']: is_training}\n",
    "        summary, step, loss_val, pred_val = sess.run([ops['merged'], ops['step'], ops['loss'], ops['pred']],\n",
    "                                      feed_dict=feed_dict)\n",
    "        test_writer.add_summary(summary, step)\n",
    "        pred_val = np.argmax(pred_val, 2)\n",
    "        correct = np.sum(pred_val == current_label[start_idx:end_idx])\n",
    "        total_correct += correct\n",
    "        total_seen += (BATCH_SIZE_EVAL*NUM_POINT)\n",
    "        loss_sum += (loss_val*BATCH_SIZE_EVAL)\n",
    "        for i in range(start_idx, end_idx):\n",
    "            for j in range(NUM_POINT):\n",
    "                l = int(current_label[i, j])\n",
    "                total_seen_class[l] += 1\n",
    "                total_correct_class[l] += (pred_val[i-start_idx, j] == l)\n",
    "            \n",
    "    log_string('eval mean loss: %f' % (loss_sum / float(total_seen/NUM_POINT)))\n",
    "    log_string('eval accuracy: %f'% (total_correct / float(total_seen)))\n",
    "    log_string('eval avg class acc: %f' % (np.mean(np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float))))\n",
    "         \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n",
    "    LOG_FOUT.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
